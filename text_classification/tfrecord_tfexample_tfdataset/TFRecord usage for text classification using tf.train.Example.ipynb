{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. *make_example*, *parse_example* functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_example(sequence, labels):\n",
    "    \"\"\"\n",
    "    create a single tf.train.Example obj instance given a single input sample\n",
    "    in the form of sequence & labels pair.\n",
    "    \"\"\"    \n",
    "    # # preprocess sequence\n",
    "    # sequence = preprocess_seq(sequence)\n",
    "    # convert sequence (string) to list of tokens ex.[string, ..., string]\n",
    "    tfrecords_features = {}\n",
    "    tfrecords_features['sequence'] = tf.train.Feature(bytes_list=tf.train.BytesList(value=[sequence.encode('utf-8')]))\n",
    "    tfrecords_features['labels'] = tf.train.Feature(bytes_list=tf.train.BytesList(value=[np.array(labels).tostring()]))\n",
    "    return tf.train.Example(features=tf.train.Features(feature=tfrecords_features))\n",
    "\n",
    "    \n",
    "def parse_exmp(serial_exmp):\n",
    "    \"\"\"\n",
    "    instructions to parse a single serialized example object, returns the \n",
    "    sequence and labels values\n",
    "    \"\"\"    \n",
    "    features = {\n",
    "        'sequence': tf.FixedLenFeature([], tf.string),\n",
    "        'labels' : tf.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    feats = tf.parse_single_example(serialized=serial_exmp, \n",
    "                                    features=features)\n",
    "    \n",
    "    sequence = feats['sequence']\n",
    "    labels   = tf.decode_raw(feats['labels'], tf.int64)\n",
    "    return sequence, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Example usage of make_example and parse_exmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialized Example:\n",
      " b'\\n\\xd5\\x06\\n\\xb1\\x06\\n\\x06labels\\x12\\xa6\\x06\\n\\xa3\\x06\\n\\xa0\\x06\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x1f\\n\\x08sequence\\x12\\x13\\n\\x11\\n\\x0ftest, test, 113'\n",
      "\n",
      "Tensors Returned From Parse_exmp:\n",
      "sequence:  Tensor(\"ParseSingleExample/ParseSingleExample:1\", shape=(), dtype=string)\n",
      "labels:  Tensor(\"DecodeRaw:0\", shape=(?,), dtype=int64)\n",
      "\n",
      "Evaluated Tensor Objects:\n",
      "sequence:  b'test, test, 113'\n",
      "labels:  [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# unit tests\n",
    "\n",
    "# make a single tf example obj\n",
    "# note: labels\n",
    "ex = make_example(sequence='test, test, 113',\n",
    "                  labels=[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "# serialize the tf example obj\n",
    "ex_serial = ex.SerializeToString()\n",
    "print('Serialized Example:\\n', ex_serial)\n",
    "print()\n",
    "\n",
    "# parse the serialized example obj\n",
    "print('Tensors Returned From Parse_exmp:')\n",
    "sequence, labels = parse_exmp(ex_serial)\n",
    "\n",
    "# examine obj type\n",
    "print('sequence: ',sequence)\n",
    "print('labels: ',labels)\n",
    "print()\n",
    "\n",
    "# evaluate each obj\n",
    "print('Evaluated Tensor Objects:')\n",
    "with tf.Session() as sess:\n",
    "    print('sequence: ', sequence.eval())\n",
    "    print('labels: ', labels.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Create a TFRecord file from input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_tfrecord(data, outf_nm='my_dataset_2'):\n",
    "    \"\"\"\n",
    "    data is in the format of tuple (sequences, labels), where each sequences and labels\n",
    "    are list objects of string sequence and label, respectively\n",
    "    \"\"\"\n",
    "    feats, labels = data\n",
    "    outf_nm += '.tfrecord'\n",
    "    tfrecord_wrt = tf.python_io.TFRecordWriter(outf_nm)\n",
    "    n_samples = len(labels)\n",
    "    for i in range(n_samples):\n",
    "        exmp = make_example(feats[i], labels[i])\n",
    "        exmp_serial = exmp.SerializeToString()\n",
    "        tfrecord_wrt.write(exmp_serial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assumed given dataset format\n",
    "\n",
    "train_sequences = ['the unbreakable “slim neck” replacement head contains wide, fanned bristles to help invigorate gum tissue for reduced chances of bleeding/receding gums and enamel erosion and is best to reach tight spaces. slim, tapered, 100% vegetable based nylon bristles reduce dependency on fossil fuels/petroleum and offer a deep clean and massage of the gumline. replacement heads are bpa-free and available in supersoft, soft, and medium bristle and can be used with the radius source toothbrush and tour travel toothbrush. all radius toothbrushes are manufactured in the usa on low-energy machines, are cruelty free, leaping bunny certified, and are 100% satisfaction guaranteed.',\n",
    "                   'the source toothbrush utilizes replacement head technology which reduces toothbrush waste by 93%! the unbreakable “slim neck” replacement head contains wide, fanned bristles to help invigorate gum tissue for reduced chances of bleeding/receding gums and enamel erosion and is best to reach tight spaces. the upcycled #5 one-of-a-kind handle contains wood, paper, or money for a beautiful, natural look & feel. reversible right or left handed design for ergonomic brushing helps reduce pressure on teeth and gums while the 100% vegetable based nylon bristles reduce dependency on fossil fuels/petroleum. the source toothbrush & replacement heads are bpa-free and available in supersoft, soft, and medium bristle. all radius toothbrushes are manufactured in the usa on low-energy machines, are cruelty free, leaping bunny certified, and are 100% satisfaction guaranteed.',\n",
    "                   'this mild foaming cleanser gently removes oil and other residues while oil-free moisturizers keep skin soft, never dry. aloe vera and extracts of cucumber, sea kelp, birch bark and lavender refresh the skin. ph 5.0 / vegan / gluten free.'\n",
    "                  ]\n",
    "\n",
    "train_labels = [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "               ]\n",
    "\n",
    "dataset = (train_sequences, train_labels)\n",
    "\n",
    "# create TFRecord file\n",
    "make_tfrecord(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Using the TFRecord file to create TFDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a tf dataset obj from the TFRecord file\n",
    "dataset = tf.data.TFRecordDataset('my_dataset_2.tfrecord')\n",
    "\n",
    "# use dataset.map() in conjunction with the parse_exmp function created earlier\n",
    "# to de-serialize each example record in TFRecord file\n",
    "dataset = dataset.map(parse_exmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# configure the dataset to set # of epoch, shuffle, and batch size \n",
    "epochs = 3\n",
    "buffer_size = len(train_labels)\n",
    "batch_size = 2\n",
    "\n",
    "# configure dataset epoch, shuffle, padding and batching operations\n",
    "dataset = dataset.repeat(epochs).shuffle(buffer_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.string, tf.int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.output_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None)]),\n",
       " TensorShape([Dimension(None), Dimension(None)]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated Tensor Objects:\n",
      "sequence:  [ b'the unbreakable \\xe2\\x80\\x9cslim neck\\xe2\\x80\\x9d replacement head contains wide, fanned bristles to help invigorate gum tissue for reduced chances of bleeding/receding gums and enamel erosion and is best to reach tight spaces. slim, tapered, 100% vegetable based nylon bristles reduce dependency on fossil fuels/petroleum and offer a deep clean and massage of the gumline. replacement heads are bpa-free and available in supersoft, soft, and medium bristle and can be used with the radius source toothbrush and tour travel toothbrush. all radius toothbrushes are manufactured in the usa on low-energy machines, are cruelty free, leaping bunny certified, and are 100% satisfaction guaranteed.'\n",
      " b'the unbreakable \\xe2\\x80\\x9cslim neck\\xe2\\x80\\x9d replacement head contains wide, fanned bristles to help invigorate gum tissue for reduced chances of bleeding/receding gums and enamel erosion and is best to reach tight spaces. slim, tapered, 100% vegetable based nylon bristles reduce dependency on fossil fuels/petroleum and offer a deep clean and massage of the gumline. replacement heads are bpa-free and available in supersoft, soft, and medium bristle and can be used with the radius source toothbrush and tour travel toothbrush. all radius toothbrushes are manufactured in the usa on low-energy machines, are cruelty free, leaping bunny certified, and are 100% satisfaction guaranteed.']\n",
      "labels:  [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# create a one-shot iterator to parse out one single record example at a time\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "sequence, labels = iterator.get_next()\n",
    "\n",
    "# evaluate each obj\n",
    "print('Evaluated Tensor Objects:')\n",
    "with tf.Session() as sess:\n",
    "    print('sequence: ', sequence.eval())\n",
    "    print('labels: ', labels.eval())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
